{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TestModel, self).__init__()\n",
    "        self.conv1a = nn.Conv2d(3, 16, (3, 3), padding=1)\n",
    "        self.conv1b = nn.Conv2d(16, 16, (3, 3), padding=1)\n",
    "        \n",
    "        self.conv2a = nn.Conv2d(16, 32, (4, 4), padding=1, stride=2)\n",
    "        self.conv2b = nn.Conv2d(32, 32, (3, 3), padding=1)\n",
    "        \n",
    "        self.conv3a = nn.Conv2d(32, 64, (4, 4), padding=1, stride=2)\n",
    "        self.conv3b = nn.Conv2d(64, 64, (3, 3), padding=1)\n",
    "        \n",
    "        self.fc1 = self.fc1 = nn.Linear(64*12*12, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "#         print(x.shape)\n",
    "        out = self.conv1a(x)\n",
    "#         print(out.shape)\n",
    "        out = F.relu(out)\n",
    "        out = self.conv1b(out)\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        out = self.conv2a(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.conv2b(out)\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        out = self.conv3a(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.conv3b(out)\n",
    "        out = F.relu(out)\n",
    "        \n",
    "#         print(out.shape)\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        \n",
    "        out = self.fc1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        \n",
    "#         print(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transforms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-12b3b3290478>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# convert each image to tensor format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m transform = transforms.Compose([\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# convert to tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m ])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transforms' is not defined"
     ]
    }
   ],
   "source": [
    "# convert each image to tensor format\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()  # convert to tensor\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "import cv2\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "\n",
    "data_path = '../Data'\n",
    "labels_path = '{}/train_labels/train_labels.csv'.format(data_path)\n",
    "\n",
    "train_labels = pd.read_csv(labels_path)\n",
    "\n",
    "print(len(train_labels))\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir):\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = '{}/{}.tif'.format(self.root_dir,\n",
    "                                self.data_frame.iloc[idx, 0])\n",
    "        img = cv2.imread(img_name)\n",
    "        img = img[24:-24,24:-24,:]\n",
    "        img = np.moveaxis(img, -1, 0)\n",
    "        \n",
    "        return torch.Tensor(img), self.data_frame.iloc[idx, 1].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchbearer\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchbearer import Trial\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import time\n",
    "\n",
    "dataset = TrainDataset(labels_path, '../Data/train')\n",
    "batch_size = 16\n",
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "random_seed= 42\n",
    "\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n",
    "                                           sampler=train_sampler)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                                sampler=valid_sampler)\n",
    "\n",
    "# trainset = TrainDataset(labels_path, '../Data/train')\n",
    "# train_loader = DataLoader(trainset, batch_size=12, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bc3fbfa887f4cb49b8ab68a3df89fb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='0/10(t)', max=11, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dom/anaconda3/envs/cancer/lib/python3.7/site-packages/torch/nn/functional.py:2016: UserWarning: Using a target size (torch.Size([15])) that is different to the input size (torch.Size([15, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f55e3d608da4426a775963b366bc642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='1/10(t)', max=11, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e65aec59d5d347179cf5ea2bc6f5cffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='2/10(t)', max=11, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c822973084674c2f9adc5d4b5b46c8ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='3/10(t)', max=11, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f68ed5572f44b22a4a8dfe9ea67414d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='4/10(t)', max=11, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "962027bd24fd4de4acd9e60687f7437c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='5/10(t)', max=11, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a65ca78ae7a488594228399ae196641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='6/10(t)', max=11, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b4b41f9018b4a74a12091c1f284cc63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='7/10(t)', max=11, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cd180ed9bd44bebaa4f4d30d4c37214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='8/10(t)', max=11, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba7811aaa9704f03bf920e9c0bf03b9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='9/10(t)', max=11, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42461d00b3cd4740b28bd9f65717bf2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='0/1(e)', max=3, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.6971936225891113, 'test_binary_acc': 0.34597155451774597}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dom/anaconda3/envs/cancer/lib/python3.7/site-packages/torch/nn/functional.py:2016: UserWarning: Using a target size (torch.Size([11])) that is different to the input size (torch.Size([11, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    }
   ],
   "source": [
    "model = TestModel()\n",
    "\n",
    "model.train()\n",
    "\n",
    "loss_function = nn.BCELoss()\n",
    "optimiser = optim.Adam(model.parameters())\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "trial = Trial(model, optimiser, loss_function, metrics=['loss', 'accuracy']).to(device)\n",
    "trial.with_generators(train_loader, test_generator=validation_loader)\n",
    "trial.run(epochs=10)\n",
    "results = trial.evaluate(data_key=torchbearer.TEST_DATA)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, 10% \t train_loss: 1.36 took: 0.18s\n",
      "Epoch 1, 21% \t train_loss: 2.79 took: 0.15s\n",
      "Epoch 1, 31% \t train_loss: 1.45 took: 0.17s\n",
      "Epoch 1, 42% \t train_loss: 1.40 took: 0.33s\n",
      "Epoch 1, 52% \t train_loss: 1.38 took: 0.20s\n",
      "Epoch 1, 63% \t train_loss: 1.19 took: 0.24s\n",
      "Epoch 1, 73% \t train_loss: 0.77 took: 0.24s\n",
      "Epoch 1, 84% \t train_loss: 2.18 took: 0.32s\n",
      "Epoch 1, 94% \t train_loss: 1.56 took: 0.19s\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1\n",
    "n_batches = len(train_loader)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    running_loss = 0.0\n",
    "    print_every = n_batches // 10\n",
    "    start_time = time.time()\n",
    "    total_train_loss = 0\n",
    "\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        #Get inputs\n",
    "        inputs, labels = data\n",
    "#         inputs.unsqueeze_(0)\n",
    "\n",
    "        #Wrap them in a Variable object\n",
    "        inputs, labels = Variable(inputs), Variable(labels).float()\n",
    "\n",
    "        #Set the parameter gradients to zero\n",
    "        optimiser.zero_grad()\n",
    "        \n",
    "        #Forward pass, backward pass, optimize\n",
    "        outputs = model(inputs)\n",
    "#         print(labels)\n",
    "        loss_size = loss_function(outputs, labels)\n",
    "        loss_size.backward()\n",
    "        optimiser.step()\n",
    "        \n",
    "#         print(loss_size)\n",
    "        \n",
    "        #Print statistics\n",
    "        running_loss += loss_size.item()\n",
    "        total_train_loss += loss_size.item()\n",
    "        \n",
    "        #Print every 10th batch of an epoch\n",
    "        if (i + 1) % (print_every + 1) == 0:\n",
    "            print(\"Epoch {}, {:d}% \\t train_loss: {:.2f} took: {:.2f}s\".format(\n",
    "                    epoch+1, int(100 * (i+1) / n_batches), running_loss / print_every, time.time() - start_time))\n",
    "            #Reset running loss and time\n",
    "            running_loss = 0.0\n",
    "            start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cancer",
   "language": "python",
   "name": "cancer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
